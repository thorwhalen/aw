{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69946bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AW (Agentic Workflows) Demo\n",
    "\n",
    "## Overview\n",
    "\n",
    "**AW** is a package for building AI agents that prepare data using the **ReAct pattern** (Reason-Act-Observe). It provides a modular, extensible framework for creating multi-step agentic workflows that can iteratively solve data preparation problems.\n",
    "\n",
    "### Why Agentic Workflows?\n",
    "\n",
    "Traditional data pipelines are rigid: if the data format changes slightly, the whole pipeline breaks. **Agentic workflows** solve this by:\n",
    "\n",
    "1. **Reasoning about the problem**: Analyzing data characteristics and requirements\n",
    "2. **Acting with generated code**: Creating transformation logic on-the-fly\n",
    "3. **Observing results**: Validating outputs and learning from failures\n",
    "4. **Iterating until success**: Automatically retrying with refined approaches\n",
    "\n",
    "This makes data preparation more **robust** and **adaptable** to varied inputs.\n",
    "\n",
    "### Core Concepts\n",
    "\n",
    "- **AgenticStep Protocol**: Common interface for all agents\n",
    "- **ReAct Pattern**: Reason → Act → Observe loop with retries\n",
    "- **Three Validation Flavors**: Schema-based, info-dict, and functional\n",
    "- **Context Management**: Shared state between workflow steps\n",
    "- **Orchestration**: Chain multiple agents into workflows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9190947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tempfile\n",
    "\n",
    "# AW package imports\n",
    "from aw import (\n",
    "    # Core abstractions\n",
    "    Context,\n",
    "    StepConfig,\n",
    "    # Agents\n",
    "    LoadingAgent,\n",
    "    PreparationAgent,\n",
    "    # Validation\n",
    "    schema_validator,\n",
    "    info_dict_validator,\n",
    "    functional_validator,\n",
    "    all_validators,\n",
    "    is_type,\n",
    "    has_attributes,\n",
    "    # Orchestration\n",
    "    AgenticWorkflow,\n",
    "    create_data_prep_workflow,\n",
    "    load_and_prepare,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6066660",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Part 1: Validation - The Three Flavors\n",
    "\n",
    "AW provides **three distinct validation approaches**, each suited to different scenarios:\n",
    "\n",
    "### 1. Schema Validation\n",
    "\n",
    "**Use when**: You have a precise structure to validate against (types, field constraints).\n",
    "\n",
    "**Pattern**: Define a Pydantic model or JSON schema, validate the artifact against it.\n",
    "\n",
    "**Best for**: APIs, structured data exchanges, type safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f966ccce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, validator\n",
    "\n",
    "# Define a schema for a data point\n",
    "class DataPoint(BaseModel):\n",
    "    x: float\n",
    "    y: float\n",
    "    label: str\n",
    "    \n",
    "    @validator('x', 'y')\n",
    "    def check_positive(cls, v):\n",
    "        if v < 0:\n",
    "            raise ValueError('coordinates must be non-negative')\n",
    "        return v\n",
    "\n",
    "# Create a validator from the schema\n",
    "validate_point = schema_validator(DataPoint)\n",
    "\n",
    "# Test with valid data\n",
    "valid_data = {'x': 1.5, 'y': 2.3, 'label': 'point_A'}\n",
    "is_valid, info = validate_point(valid_data)\n",
    "print(f\"Valid: {is_valid}\")\n",
    "print(f\"Validated object: {info['validated']}\")\n",
    "\n",
    "# Test with invalid data\n",
    "invalid_data = {'x': -1.0, 'y': 2.3, 'label': 'point_B'}\n",
    "is_valid, info = validate_point(invalid_data)\n",
    "print(f\"\\nValid: {is_valid}\")\n",
    "print(f\"Error: {info.get('error', 'N/A')[:100]}...\")  # Truncate long error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c0c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. Info-Dict Validation\n",
    "\n",
    "**Use when**: You need to compute statistics/properties and check them against requirements.\n",
    "\n",
    "**Pattern**: `compute_info(artifact) → check_info(info) → (bool, info)`\n",
    "\n",
    "**Best for**: Data quality checks, statistical validation, multi-step analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1ca0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'x': [1.0, 2.0, 3.0, 4.0, 5.0],\n",
    "    'y': [2.0, 4.0, 6.0, 8.0, 10.0],\n",
    "    'category': ['A', 'B', 'A', 'B', 'A']\n",
    "})\n",
    "\n",
    "# Define compute function (extract statistics)\n",
    "def compute_df_info(df):\n",
    "    return {\n",
    "        'n_rows': len(df),\n",
    "        'n_cols': len(df.columns),\n",
    "        'null_count': df.isnull().sum().sum(),\n",
    "        'numeric_cols': list(df.select_dtypes(include='number').columns),\n",
    "        'memory_mb': df.memory_usage(deep=True).sum() / 1024**2\n",
    "    }\n",
    "\n",
    "# Define check function (validate computed info)\n",
    "def check_df_requirements(info):\n",
    "    errors = []\n",
    "    \n",
    "    if info['n_rows'] < 3:\n",
    "        errors.append('Need at least 3 rows')\n",
    "    \n",
    "    if info['null_count'] > 0:\n",
    "        errors.append(f\"Found {info['null_count']} null values\")\n",
    "    \n",
    "    if len(info['numeric_cols']) < 2:\n",
    "        errors.append('Need at least 2 numeric columns')\n",
    "    \n",
    "    if errors:\n",
    "        return False, {'errors': errors, 'info': info}\n",
    "    \n",
    "    return True, {'status': 'passed', 'info': info}\n",
    "\n",
    "# Create and use the validator\n",
    "validate_df = info_dict_validator(compute_df_info, check_df_requirements)\n",
    "\n",
    "is_valid, result = validate_df(df)\n",
    "print(f\"Valid: {is_valid}\")\n",
    "print(f\"Info: {result['info']}\")\n",
    "print(f\"Reason: {result.get('reason', 'OK')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d0fa55",
   "metadata": {},
   "source": [
    "### 3. Functional Validation\n",
    "\n",
    "**Use when**: The best test is whether you can actually **use** the artifact for its intended purpose.\n",
    "\n",
    "**Pattern**: Try the actual use case (e.g., visualization, model training) and catch any errors.\n",
    "\n",
    "**Best for**: Integration testing, end-to-end validation, \"does it actually work?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242df571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Validate that we can actually plot the data\n",
    "def try_to_plot(df):\n",
    "    \"\"\"Attempt to create a scatter plot - this is the 'purpose' test.\"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # This will raise if df doesn't have numeric columns or has issues\n",
    "    fig, ax = plt.subplots(figsize=(6, 4))\n",
    "    numeric_cols = df.select_dtypes(include='number').columns\n",
    "    \n",
    "    if len(numeric_cols) < 2:\n",
    "        raise ValueError(f\"Need at least 2 numeric columns, got {len(numeric_cols)}\")\n",
    "    \n",
    "    ax.scatter(df[numeric_cols[0]], df[numeric_cols[1]])\n",
    "    ax.set_xlabel(numeric_cols[0])\n",
    "    ax.set_ylabel(numeric_cols[1])\n",
    "    plt.close(fig)  # Close to avoid display\n",
    "    \n",
    "    return {'plotted': True, 'x_col': numeric_cols[0], 'y_col': numeric_cols[1]}\n",
    "\n",
    "# Create functional validator\n",
    "validate_plotable = functional_validator(try_to_plot)\n",
    "\n",
    "# Test with good data\n",
    "is_valid, result = validate_plotable(df)\n",
    "print(f\"Valid: {is_valid}\")\n",
    "print(f\"Result: {result}\")\n",
    "\n",
    "# Test with bad data (no numeric columns)\n",
    "bad_df = pd.DataFrame({'name': ['Alice', 'Bob'], 'city': ['NYC', 'LA']})\n",
    "is_valid, result = validate_plotable(bad_df)\n",
    "print(f\"\\nBad data - Valid: {is_valid}\")\n",
    "print(f\"Error: {result.get('error', 'N/A')[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f1f140",
   "metadata": {},
   "source": [
    "### Combining Validators\n",
    "\n",
    "Validators can be **composed** for multi-stage validation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff55f6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine: must be DataFrame AND must be non-empty AND must be plottable\n",
    "from aw import is_not_empty\n",
    "\n",
    "combined_validator = all_validators(\n",
    "    is_type(pd.DataFrame),\n",
    "    is_not_empty(),\n",
    "    validate_plotable\n",
    ")\n",
    "\n",
    "# Test\n",
    "is_valid, result = combined_validator(df)\n",
    "print(f\"All checks passed: {is_valid}\")\n",
    "print(f\"Details: {result}\")\n",
    "\n",
    "# Test with empty DataFrame\n",
    "empty_df = pd.DataFrame()\n",
    "is_valid, result = combined_validator(empty_df)\n",
    "print(f\"\\nEmpty df - Valid: {is_valid}\")\n",
    "print(f\"Failed validators: {[k for k, v in result.items() if not v.get('success', True)]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55eb965d",
   "metadata": {},
   "source": [
    "## Part 2: Context - Shared State Across Steps\n",
    "\n",
    "The **Context** object is a mutable mapping that stores artifacts and metadata as they flow through the workflow.\n",
    "\n",
    "### Why Context?\n",
    "\n",
    "- **State sharing**: Later steps can access artifacts from earlier steps\n",
    "- **History tracking**: Automatically tracks all state updates\n",
    "- **Debugging**: Snapshot the context at any point to understand what happened\n",
    "- **Mapping interface**: Works like a dict but with extra capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac42198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a context\n",
    "ctx = Context()\n",
    "\n",
    "# Store results from a \"loading\" step\n",
    "ctx['loading'] = {\n",
    "    'df': df,\n",
    "    'metadata': {'source': 'demo.csv', 'rows': len(df)}\n",
    "}\n",
    "\n",
    "# Store results from a \"preparing\" step\n",
    "ctx['preparing'] = {\n",
    "    'df': df.copy(),\n",
    "    'metadata': {'transformations': ['dropna', 'normalize']}\n",
    "}\n",
    "\n",
    "# Access like a dict\n",
    "print(f\"Loading metadata: {ctx['loading']['metadata']}\")\n",
    "\n",
    "# View history\n",
    "print(f\"\\nHistory (length {len(ctx.history)}):\") \n",
    "for key, value in ctx.history:\n",
    "    print(f\"  - Set '{key}' with {len(str(value))} characters\")\n",
    "\n",
    "# Take a snapshot\n",
    "snapshot = ctx.snapshot()\n",
    "print(f\"\\nSnapshot keys: {list(snapshot.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9742693e",
   "metadata": {},
   "source": [
    "## Part 3: The LoadingAgent - Data Ingestion with Intelligence\n",
    "\n",
    "The **LoadingAgent** automatically loads data from various sources into pandas DataFrames.\n",
    "\n",
    "### How it Works (ReAct Pattern)\n",
    "\n",
    "1. **Sample**: Read file metadata (extension, first 1KB)\n",
    "2. **Reason**: Infer the loader function and parameters\n",
    "3. **Act**: Generate and execute loading code\n",
    "4. **Observe**: Validate the result is a non-empty DataFrame\n",
    "5. **Retry**: If failed, analyze error and try different approach\n",
    "\n",
    "### Why Not Just `pd.read_csv()`?\n",
    "\n",
    "- Handles multiple formats (CSV, Excel, JSON, Parquet, etc.)\n",
    "- Automatically detects encoding issues\n",
    "- Tries different delimiters/parameters on failure\n",
    "- Provides rich metadata about the loading process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022af447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some test data files\n",
    "temp_dir = Path(tempfile.mkdtemp())\n",
    "\n",
    "# Simple CSV\n",
    "csv_path = temp_dir / 'data.csv'\n",
    "test_df = pd.DataFrame({\n",
    "    'id': range(1, 11),\n",
    "    'x': np.random.randn(10),\n",
    "    'y': np.random.randn(10),\n",
    "    'category': np.random.choice(['A', 'B', 'C'], 10)\n",
    "})\n",
    "test_df.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"Created test CSV at: {csv_path}\")\n",
    "print(f\"Original data shape: {test_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(test_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6875675",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a LoadingAgent\n",
    "loading_agent = LoadingAgent()\n",
    "\n",
    "# Create context\n",
    "context = Context()\n",
    "\n",
    "# Execute loading\n",
    "loaded_df, metadata = loading_agent.execute(str(csv_path), context)\n",
    "\n",
    "# Check results\n",
    "print(f\"Success: {metadata['success']}\")\n",
    "print(f\"Loaded shape: {loaded_df.shape if loaded_df is not None else 'None'}\")\n",
    "print(f\"Number of attempts: {metadata.get('num_attempts', 'N/A')}\")\n",
    "\n",
    "# View DataFrame info from metadata\n",
    "if 'df_info' in metadata:\n",
    "    print(f\"\\nDataFrame info:\")\n",
    "    for key, value in metadata['df_info'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "# Check what's in context\n",
    "print(f\"\\nContext keys: {list(context.keys())}\")\n",
    "if 'loading' in context:\n",
    "    print(f\"Loading context keys: {list(context['loading'].keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77d0bc3",
   "metadata": {},
   "source": [
    "## Part 4: The PreparationAgent - Intelligent Data Transformation\n",
    "\n",
    "The **PreparationAgent** transforms data to meet specific requirements using functional validation.\n",
    "\n",
    "### How it Works\n",
    "\n",
    "1. **Analyze**: Compute initial data statistics\n",
    "2. **Reason**: Determine what transformations are needed\n",
    "3. **Act**: Generate and execute transformation code\n",
    "4. **Observe**: Apply the **target validator** (functional test)\n",
    "5. **Retry**: If validation fails, analyze error and try different transformation\n",
    "\n",
    "### Target-Driven Design\n",
    "\n",
    "Instead of specifying exact transformations, you specify the **target** (e.g., 'cosmo-ready', 'ml-ready') and a **validator** that checks if the data meets that target's requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3da73bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a custom validator for \"plotting-ready\" data\n",
    "def validate_plot_ready(df):\n",
    "    \"\"\"Data is plot-ready if it has at least 2 numeric columns with no nulls.\"\"\"\n",
    "    try:\n",
    "        numeric_cols = df.select_dtypes(include='number').columns\n",
    "        \n",
    "        if len(numeric_cols) < 2:\n",
    "            return False, {\n",
    "                'error': f'Need at least 2 numeric columns, found {len(numeric_cols)}',\n",
    "                'numeric_cols': list(numeric_cols)\n",
    "            }\n",
    "        \n",
    "        # Check for nulls in numeric columns\n",
    "        null_counts = df[numeric_cols].isnull().sum()\n",
    "        if null_counts.sum() > 0:\n",
    "            return False, {\n",
    "                'error': 'Found null values in numeric columns',\n",
    "                'null_counts': null_counts.to_dict()\n",
    "            }\n",
    "        \n",
    "        return True, {\n",
    "            'status': 'plot-ready',\n",
    "            'numeric_cols': list(numeric_cols),\n",
    "            'shape': df.shape\n",
    "        }\n",
    "    except Exception as e:\n",
    "        return False, {'error': str(e)}\n",
    "\n",
    "# Create PreparationAgent with this validator\n",
    "config = StepConfig(validator=validate_plot_ready, max_retries=2)\n",
    "prep_agent = PreparationAgent(config=config, target='plot-ready')\n",
    "\n",
    "# Use the loaded DataFrame from previous step\n",
    "# (In a real workflow, this would come from context)\n",
    "prepared_df, prep_metadata = prep_agent.execute(loaded_df, context)\n",
    "\n",
    "print(f\"Success: {prep_metadata['success']}\")\n",
    "print(f\"Number of attempts: {prep_metadata.get('num_attempts', 'N/A')}\")\n",
    "\n",
    "if 'validation_result' in prep_metadata:\n",
    "    print(f\"\\nValidation result:\")\n",
    "    for key, value in prep_metadata['validation_result'].items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "if prepared_df is not None:\n",
    "    print(f\"\\nPrepared data shape: {prepared_df.shape}\")\n",
    "    print(f\"Columns: {list(prepared_df.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07318042",
   "metadata": {},
   "source": [
    "## Part 5: Workflows - Orchestrating Multiple Agents\n",
    "\n",
    "**AgenticWorkflow** chains multiple agents together, managing context and artifact passing.\n",
    "\n",
    "### Why Workflows?\n",
    "\n",
    "- **Modularity**: Each agent focuses on one task\n",
    "- **Reusability**: Mix and match agents for different pipelines\n",
    "- **Observability**: Track execution of each step\n",
    "- **Failure handling**: Know exactly where/why things failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3011c7f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual workflow construction\n",
    "workflow = AgenticWorkflow()\n",
    "\n",
    "# Add loading step\n",
    "workflow.add_step('loading', LoadingAgent())\n",
    "\n",
    "# Add preparing step\n",
    "prep_config = StepConfig(validator=validate_plot_ready, max_retries=2)\n",
    "workflow.add_step(\n",
    "    'preparing', \n",
    "    PreparationAgent(config=prep_config, target='plot-ready')\n",
    ")\n",
    "\n",
    "# Execute workflow\n",
    "final_artifact, workflow_metadata = workflow.run(str(csv_path))\n",
    "\n",
    "print(f\"Workflow success: {workflow_metadata.get('success', False)}\")\n",
    "print(f\"\\nSteps executed:\")\n",
    "for step_info in workflow_metadata['steps']:\n",
    "    print(f\"  - {step_info['name']}: {step_info.get('success', 'N/A')}\")\n",
    "\n",
    "# Final result\n",
    "if final_artifact is not None:\n",
    "    print(f\"\\nFinal artifact shape: {final_artifact.shape}\")\n",
    "    print(f\"Ready to plot!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4a69122",
   "metadata": {},
   "source": [
    "### Workflow Factories\n",
    "\n",
    "For common patterns, use **factory functions** for convenience:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4132845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use factory function\n",
    "workflow = create_data_prep_workflow(target='plot-ready')\n",
    "\n",
    "# Or use the convenience function directly\n",
    "result_df, result_metadata = load_and_prepare(\n",
    "    str(csv_path),\n",
    "    target='plot-ready',\n",
    "    validator=validate_plot_ready,\n",
    "    max_retries=2\n",
    ")\n",
    "\n",
    "print(f\"Success: {result_metadata.get('success', False)}\")\n",
    "if result_df is not None:\n",
    "    print(f\"Result shape: {result_df.shape}\")\n",
    "    print(f\"\\nFirst few rows:\")\n",
    "    print(result_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3442973c",
   "metadata": {},
   "source": [
    "## Part 6: Real-World Example - Preparing for Cosmograph\n",
    "\n",
    "**Cosmograph** is a visualization library that requires specific data formats. Let's use AW to automatically prepare data for it.\n",
    "\n",
    "### Cosmograph Requirements\n",
    "\n",
    "- At least 2 numeric columns (for x/y coordinates)\n",
    "- No null values in coordinate columns\n",
    "- Optional: labels, colors, sizes from other columns\n",
    "\n",
    "AW provides specialized validators for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bcc3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aw.cosmo import basic_cosmo_validator, infer_cosmo_params\n",
    "from aw import load_for_cosmo\n",
    "\n",
    "# Create test data with some issues\n",
    "messy_csv = temp_dir / 'messy_data.csv'\n",
    "messy_df = pd.DataFrame({\n",
    "    'id': range(1, 21),\n",
    "    'feature_1': np.random.randn(20),\n",
    "    'feature_2': np.random.randn(20),\n",
    "    'feature_3': np.random.randn(20),\n",
    "    'label': np.random.choice(['A', 'B', 'C'], 20),\n",
    "    'notes': ['note_' + str(i) for i in range(20)]\n",
    "})\n",
    "# Add some nulls\n",
    "messy_df.loc[2, 'feature_1'] = None\n",
    "messy_df.loc[5, 'feature_2'] = None\n",
    "\n",
    "messy_df.to_csv(messy_csv, index=False)\n",
    "\n",
    "print(f\"Created messy data with nulls:\")\n",
    "print(f\"Shape: {messy_df.shape}\")\n",
    "print(f\"Null counts:\\n{messy_df.isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85634352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cosmo-specific workflow\n",
    "# Note: This will use basic_cosmo_validator which doesn't actually call cosmograph\n",
    "# (to avoid the dependency), but validates the structure is correct\n",
    "\n",
    "cosmo_df, cosmo_metadata = load_for_cosmo(str(messy_csv), max_retries=3)\n",
    "\n",
    "print(f\"Success: {cosmo_metadata.get('success', False)}\")\n",
    "\n",
    "if cosmo_df is not None:\n",
    "    print(f\"\\nCleaned data shape: {cosmo_df.shape}\")\n",
    "    print(f\"Null counts: {cosmo_df.isnull().sum().sum()}\")\n",
    "    print(f\"\\nNumeric columns: {list(cosmo_df.select_dtypes(include='number').columns)}\")\n",
    "    \n",
    "    # Infer cosmograph parameters\n",
    "    if 'preparing' in cosmo_metadata:\n",
    "        validation_result = cosmo_metadata['preparing']['metadata'].get('validation_result', {})\n",
    "        if 'params' in validation_result:\n",
    "            print(f\"\\nSuggested cosmograph params:\")\n",
    "            for key, value in validation_result['params'].items():\n",
    "                print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcfb835",
   "metadata": {},
   "source": [
    "## Part 7: Advanced - Custom Agents\n",
    "\n",
    "You can build your own agents by following the **AgenticStep protocol**:\n",
    "\n",
    "```python\n",
    "def execute(self, input_data: Any, context: MutableMapping[str, Any]) -> tuple[Artifact, dict]:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Let's create a simple **FilteringAgent** that removes outliers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4997c2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from collections.abc import MutableMapping\n",
    "\n",
    "class OutlierFilterAgent:\n",
    "    \"\"\"Simple agent that removes outliers using IQR method.\"\"\"\n",
    "    \n",
    "    def __init__(self, threshold: float = 1.5):\n",
    "        self.threshold = threshold\n",
    "    \n",
    "    def execute(\n",
    "        self, \n",
    "        input_df: pd.DataFrame, \n",
    "        context: MutableMapping[str, Any]\n",
    "    ) -> tuple[pd.DataFrame, dict[str, Any]]:\n",
    "        \"\"\"Remove outliers from numeric columns.\"\"\"\n",
    "        \n",
    "        df = input_df.copy()\n",
    "        initial_count = len(df)\n",
    "        \n",
    "        removed_per_column = {}\n",
    "        \n",
    "        # For each numeric column\n",
    "        for col in df.select_dtypes(include='number').columns:\n",
    "            Q1 = df[col].quantile(0.25)\n",
    "            Q3 = df[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            \n",
    "            # Define outlier bounds\n",
    "            lower_bound = Q1 - self.threshold * IQR\n",
    "            upper_bound = Q3 + self.threshold * IQR\n",
    "            \n",
    "            # Count outliers\n",
    "            outliers = (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "            removed_per_column[col] = outliers.sum()\n",
    "            \n",
    "            # Remove outliers\n",
    "            df = df[~outliers]\n",
    "        \n",
    "        final_count = len(df)\n",
    "        \n",
    "        metadata = {\n",
    "            'success': True,\n",
    "            'initial_rows': initial_count,\n",
    "            'final_rows': final_count,\n",
    "            'removed_total': initial_count - final_count,\n",
    "            'removed_per_column': removed_per_column,\n",
    "            'threshold': self.threshold\n",
    "        }\n",
    "        \n",
    "        # Store in context\n",
    "        context['outlier_filtering'] = {\n",
    "            'df': df,\n",
    "            'metadata': metadata\n",
    "        }\n",
    "        \n",
    "        return df, metadata\n",
    "\n",
    "# Test the custom agent\n",
    "test_data = pd.DataFrame({\n",
    "    'x': [1, 2, 3, 4, 5, 100],  # 100 is outlier\n",
    "    'y': [2, 4, 6, 8, 10, 12],\n",
    "    'z': [-50, 5, 6, 7, 8, 9]   # -50 is outlier\n",
    "})\n",
    "\n",
    "print(\"Before filtering:\")\n",
    "print(test_data)\n",
    "\n",
    "filter_agent = OutlierFilterAgent(threshold=1.5)\n",
    "ctx = Context()\n",
    "\n",
    "filtered_df, filter_meta = filter_agent.execute(test_data, ctx)\n",
    "\n",
    "print(f\"\\nAfter filtering:\")\n",
    "print(filtered_df)\n",
    "print(f\"\\nRemoved {filter_meta['removed_total']} outliers\")\n",
    "print(f\"Per column: {filter_meta['removed_per_column']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02a02e2",
   "metadata": {},
   "source": [
    "### Integrate Custom Agent into Workflow\n",
    "\n",
    "Custom agents work seamlessly with built-in ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d644dff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a workflow with custom agent\n",
    "custom_workflow = AgenticWorkflow()\n",
    "\n",
    "# Step 1: Load\n",
    "custom_workflow.add_step('loading', LoadingAgent())\n",
    "\n",
    "# Step 2: Filter outliers (custom!)\n",
    "custom_workflow.add_step('filtering', OutlierFilterAgent(threshold=2.0))\n",
    "\n",
    "# Step 3: Prepare for visualization\n",
    "prep_config = StepConfig(validator=validate_plot_ready, max_retries=2)\n",
    "custom_workflow.add_step(\n",
    "    'preparing',\n",
    "    PreparationAgent(config=prep_config, target='plot-ready')\n",
    ")\n",
    "\n",
    "# Run complete workflow\n",
    "final_result, final_metadata = custom_workflow.run(str(csv_path))\n",
    "\n",
    "print(f\"Workflow success: {final_metadata.get('success', False)}\")\n",
    "print(f\"\\nSteps:\")\n",
    "for step in final_metadata['steps']:\n",
    "    print(f\"  {step['name']}: {step.get('success', 'N/A')}\")\n",
    "\n",
    "# Check what each step did\n",
    "if 'outlier_filtering' in custom_workflow.context:\n",
    "    filter_info = custom_workflow.context['outlier_filtering']['metadata']\n",
    "    print(f\"\\nFiltering removed {filter_info['removed_total']} rows\")\n",
    "\n",
    "if final_result is not None:\n",
    "    print(f\"\\nFinal result shape: {final_result.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3519f37f",
   "metadata": {},
   "source": [
    "## Summary: Key Takeaways\n",
    "\n",
    "### 1. **Three Validation Flavors**\n",
    "   - **Schema**: Strict type/structure validation\n",
    "   - **Info-dict**: Compute stats → check requirements\n",
    "   - **Functional**: Try the actual use case\n",
    "\n",
    "### 2. **ReAct Pattern**\n",
    "   - Reason → Act → Observe → Retry\n",
    "   - Makes pipelines robust to varied inputs\n",
    "   - Automatic error analysis and recovery\n",
    "\n",
    "### 3. **Modular Agents**\n",
    "   - Each agent has single responsibility\n",
    "   - Easy to test, reuse, and compose\n",
    "   - Follow `AgenticStep` protocol\n",
    "\n",
    "### 4. **Context Management**\n",
    "   - Shared state across workflow steps\n",
    "   - History tracking for debugging\n",
    "   - Dict-like interface\n",
    "\n",
    "### 5. **Orchestration**\n",
    "   - Chain agents into workflows\n",
    "   - Factory functions for common patterns\n",
    "   - Detailed execution metadata\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore the `aw.cosmo` module for cosmograph integration\n",
    "- Build custom agents for your domain\n",
    "- Integrate with real LLMs (OpenAI, Anthropic) for more sophisticated reasoning\n",
    "- Add human-in-the-loop with `InteractiveWorkflow`\n",
    "- Extend with more validation patterns\n",
    "\n",
    "### Documentation\n",
    "\n",
    "See the full README and test suite for more examples and patterns!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
